# Woodpecker: Hallucination Correction for Multimodal Large Language Models

## Project Overview

**Woodpecker** is a training-free post-remedy system designed to detect and correct hallucinations in Multimodal Large Language Models (MLLMs). Hallucinations refer to generated text that is inconsistent with the actual image content. Unlike existing approaches that require retraining models, Woodpecker operates as a post-processing correction pipeline that can be applied to any MLLM without modification.

### Key Innovation
- **Training-free**: No model retraining required
- **Universal compatibility**: Works with any MLLM (LLaVA, mPLUG-Owl, MiniGPT-4, Otter)
- **Interpretable**: Provides intermediate outputs at each stage
- **Significant improvements**: 30.66%/24.33% accuracy improvement over baseline models

---

## ğŸ†• **Project Modifications: Original vs. Enhanced**

This project is based on the original **Woodpecker** repository from GitHub, with significant enhancements and additions. Below is a clear breakdown of what was original and what we added:

### **Original Woodpecker System (from GitHub)**

The original Woodpecker project includes:

1. **Five-Stage Correction Pipeline** (Core System)
   - PreProcessor: Sentence splitting
   - EntityExtractor: Named entity extraction using spaCy
   - Detector: Object detection using GroundingDINO
   - Questioner: Question generation using GPT API
   - Answerer: Visual QA using BLIP-2
   - ClaimGenerator: Claim generation using QA2Claim model
   - Refiner: Text refinement using GPT API

2. **Original Inference Scripts**
   - `inference_single.py` (or `inference.py`): Single sample inference
   - `gradio_demo.py`: Web-based demo interface
   - Basic correction pipeline execution

3. **Core Models**
   - All correction pipeline components (`models/preprocessor.py`, `models/entity_extractor.py`, etc.)
   - `vis_corrector.py`: Main corrector orchestrator

### **ğŸ†• Our Additions and Enhancements**

We have significantly extended the original Woodpecker system with the following additions:

#### **1. Hallucination Confidence Scoring (HCS) System** â­ **NEW**
   - **`modules/hallucination_detector.py`**: Complete HCS module implementation
   - **Purpose**: Provides quantitative hallucination detection without correction
   - **Integration**: Can be used independently or alongside correction pipeline

#### **2. Enhanced Inference Scripts** â­ **NEW**
   - **`inference_chunked.py`**: Batch/chunked processing with CLIP scoring
   - **`inference_batch.py`**: Simple batch inference
   - **Enhanced `inference_single.py`**: Added HCS integration

#### **3. HCS Computation Scripts** â­ **NEW**
   - **`compute_hcs_only.py`**: Standalone HCS computation
   - **`compute_hcs_parallel.py`**: Parallel HCS wrapper

#### **4. Dataset Preparation** â­ **NEW**
   - **`coco_to_pairs.py`**: Converts COCO annotations to image-caption pairs

#### **5. Bug Fixes and Optimizations** â­ **ENHANCED**
   - Boundary clipping fix in `models/detector.py`
   - Performance optimizations (caching, global loading, CUDA optimizations)

### **Summary of Changes**

| Component | Status | Description |
|-----------|--------|-------------|
| Correction Pipeline (5 stages) | âœ… Original | Core Woodpecker system from GitHub |
| HCS Scoring System | ğŸ†• **NEW** | Complete new module for hallucination scoring |
| `compute_hcs_only.py` | ğŸ†• **NEW** | Standalone HCS computation script |
| `compute_hcs_parallel.py` | ğŸ†• **NEW** | Parallel HCS processing wrapper |
| `inference_chunked.py` | ğŸ†• **NEW** | Enhanced batch inference with CLIP scoring |
| `inference_batch.py` | ğŸ†• **NEW** | Simple batch inference script |
| `coco_to_pairs.py` | ğŸ†• **NEW** | Dataset preparation utility |
| Boundary clipping fix | ğŸ”§ **FIXED** | Bug fix in detector.py |
| Performance optimizations | âš¡ **ENHANCED** | Caching, global loading, CUDA optimizations |
| Enhanced `inference_single.py` | ğŸ”„ **MODIFIED** | Added HCS integration |

---

## Architecture

This section presents the system architecture in three parts: **Original Woodpecker**, **Our Additions**, and **Combined Enhanced System**.

---

### 1. Original Woodpecker Architecture âœ… **From GitHub**

#### 1.1 System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ORIGINAL WOODPECKER SYSTEM (GitHub)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Image (PIL Image / File Path)                                    â”‚
â”‚  â€¢ Query Text (e.g., "Describe this image.")                        â”‚
â”‚  â€¢ Generated Caption (from MLLM)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CORRECTION PIPELINE (5 Stages) âœ… Original             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 1: PreProcessor                                       â”‚   â”‚
â”‚  â”‚   â€¢ Sentence splitting                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 2: EntityExtractor                                    â”‚   â”‚
â”‚  â”‚   â€¢ spaCy NLP                                               â”‚   â”‚
â”‚  â”‚   â€¢ Entity extraction                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 3: Detector (GroundingDINO)                          â”‚   â”‚
â”‚  â”‚   â€¢ Object detection                                        â”‚   â”‚
â”‚  â”‚   â€¢ Bounding box extraction                                â”‚   â”‚
â”‚  â”‚   â€¢ Region cropping & caching                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 4: Questioner (GPT API)                              â”‚   â”‚
â”‚  â”‚   â€¢ Question generation                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 5: Answerer (BLIP-2)                                 â”‚   â”‚
â”‚  â”‚   â€¢ Visual QA                                              â”‚   â”‚
â”‚  â”‚   â€¢ Answer generation                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 6: ClaimGenerator (QA2Claim T5)                      â”‚   â”‚
â”‚  â”‚   â€¢ Claim generation                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 7: Refiner (GPT API)                                 â”‚   â”‚
â”‚  â”‚   â€¢ Text refinement                                        â”‚   â”‚
â”‚  â”‚   â€¢ Final correction                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT LAYER âœ… Original                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Corrected Caption                                                â”‚
â”‚  â€¢ Intermediate Results (sentences, entities, detections, Q&A)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1.2 Original Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ORIGINAL WOODPECKER DATA FLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input: Single Image + Caption
    â”‚
    â”œâ”€â†’ inference_single.py (or inference.py) âœ… Original
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Load image + caption
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Run Correction Pipeline:
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€â†’ PreProcessor: Split sentences
    â”‚       â”‚       â”œâ”€â†’ EntityExtractor: Extract entities
    â”‚       â”‚       â”œâ”€â†’ Detector: Detect objects
    â”‚       â”‚       â”œâ”€â†’ Questioner: Generate questions
    â”‚       â”‚       â”œâ”€â†’ Answerer: Answer questions
    â”‚       â”‚       â”œâ”€â†’ ClaimGenerator: Generate claims
    â”‚       â”‚       â””â”€â†’ Refiner: Refine text
    â”‚       â”‚
    â”‚       â””â”€â†’ Output: Corrected caption + intermediate results
    â”‚               â”‚
    â”‚               â””â”€â†’ Saved to: intermediate_view.json
```

---

### 2. Our Additions Architecture ğŸ†• **New Components**

#### 2.1 HCS Scoring System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              HCS SCORING SYSTEM ğŸ†• NEW                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: Image + Caption                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Entity Extraction                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Extract entities from caption text                              â”‚
â”‚  â€¢ Simple token-based extraction with stop-word filtering          â”‚
â”‚  Output: List of entities                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Object Detection                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Use GroundingDINO to detect entities in image                  â”‚
â”‚  â€¢ Match text entities with visual detections                      â”‚
â”‚  â€¢ Extract bounding boxes and detection counts                     â”‚
â”‚  Output: Entity detection information                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Score Calculation                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Calculate three sub-scores:                                        â”‚
â”‚                                                                      â”‚
â”‚  1. Entity Coverage Score (40% weight)                            â”‚
â”‚     â€¢ Ratio of text entities detected in image                     â”‚
â”‚                                                                      â”‚
â”‚  2. Spatial Consistency Score (30% weight)                         â”‚
â”‚     â€¢ Consistency of spatial relationships                          â”‚
â”‚                                                                      â”‚
â”‚  3. Detection Confidence Score (30% weight)                        â”‚
â”‚     â€¢ Quality and confidence of detections                         â”‚
â”‚                                                                      â”‚
â”‚  Overall HCS = 0.4 Ã— Coverage + 0.3 Ã— Spatial + 0.3 Ã— Conf        â”‚
â”‚  Output: HCS score (0-1, higher = less hallucination)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.2 Enhanced Inference Scripts Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ENHANCED INFERENCE SCRIPTS ğŸ†• NEW                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Script 1: inference_chunked.py ğŸ†• NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Batch/chunked processing for large datasets
â€¢ CLIP similarity computation
â€¢ Multi-GPU support
â€¢ Auto-resume functionality
â€¢ DataLoader-based batch processing


Script 2: compute_hcs_only.py ğŸ†• NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Standalone HCS computation
â€¢ Processes pre-generated captions from JSONL
â€¢ Caption caching for duplicates
â€¢ Checkpoint saving and resume
â€¢ GPU memory optimizations


Script 3: compute_hcs_parallel.py ğŸ†• NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Parallel wrapper for HCS computation
â€¢ Multi-worker processing
â€¢ GPU assignment per worker
â€¢ Automatic chunk splitting and merging
â€¢ Progress tracking
```

---

### 3. Combined Enhanced Architecture ğŸ†• **Original + Our Additions**

#### 3.1 Complete System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ENHANCED WOODPECKER SYSTEM (Original + Our Additions)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Image (PIL Image / File Path)                                    â”‚
â”‚  â€¢ Query Text (e.g., "Describe this image.")                        â”‚
â”‚  â€¢ Generated Caption (from MLLM) [Optional]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAPTION GENERATION LAYER (Optional)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚   BLIP-2 Model   â”‚  â†’  Generates initial caption                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CORRECTION PIPELINE (5 Stages) âœ… Original             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 1: PreProcessor                                       â”‚   â”‚
â”‚  â”‚   â€¢ Sentence splitting                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 2: EntityExtractor                                    â”‚   â”‚
â”‚  â”‚   â€¢ spaCy NLP                                               â”‚   â”‚
â”‚  â”‚   â€¢ Entity extraction                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 3: Detector (GroundingDINO)                          â”‚   â”‚
â”‚  â”‚   â€¢ Object detection                                        â”‚   â”‚
â”‚  â”‚   â€¢ Bounding box extraction                                â”‚   â”‚
â”‚  â”‚   â€¢ Region cropping & caching                              â”‚   â”‚
â”‚  â”‚   ğŸ”§ Enhanced: Boundary clipping fix                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 4: Questioner (GPT API)                              â”‚   â”‚
â”‚  â”‚   â€¢ Question generation                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 5: Answerer (BLIP-2)                                 â”‚   â”‚
â”‚  â”‚   â€¢ Visual QA                                              â”‚   â”‚
â”‚  â”‚   â€¢ Answer generation                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 6: ClaimGenerator (QA2Claim T5)                      â”‚   â”‚
â”‚  â”‚   â€¢ Claim generation                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚                              â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Stage 7: Refiner (GPT API)                                 â”‚   â”‚
â”‚  â”‚   â€¢ Text refinement                                        â”‚   â”‚
â”‚  â”‚   â€¢ Final correction                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVALUATION LAYER ğŸ†• NEW                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚   CLIP Model     â”‚      â”‚   HCS Scorer ğŸ†•   â”‚                    â”‚
â”‚  â”‚   âš¡ Enhanced    â”‚      â”‚                  â”‚                    â”‚
â”‚  â”‚                  â”‚      â”‚ â€¢ Entity         â”‚                    â”‚
â”‚  â”‚ â€¢ Image-text     â”‚      â”‚   coverage      â”‚                    â”‚
â”‚  â”‚   similarity     â”‚      â”‚ â€¢ Spatial        â”‚                    â”‚
â”‚  â”‚ â€¢ Cosine         â”‚      â”‚   consistency    â”‚                    â”‚
â”‚  â”‚   similarity     â”‚      â”‚ â€¢ Detection      â”‚                    â”‚
â”‚  â”‚                  â”‚      â”‚   confidence     â”‚                    â”‚
â”‚  â”‚ â€¢ Generated vs   â”‚      â”‚                  â”‚                    â”‚
â”‚  â”‚   Ground Truth   â”‚      â”‚                  â”‚                    â”‚
â”‚  â”‚ â€¢ Corrected vs    â”‚      â”‚                  â”‚                    â”‚
â”‚  â”‚   Ground Truth   â”‚      â”‚                  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT LAYER ğŸ†• Enhanced                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Corrected Caption                                                â”‚
â”‚  â€¢ CLIP Similarity Scores âš¡ NEW                                   â”‚
â”‚  â€¢ HCS Score ğŸ†• NEW                                                 â”‚
â”‚  â€¢ HCS Score Breakdown ğŸ†• NEW                                       â”‚
â”‚  â€¢ Intermediate Results (sentences, entities, detections, Q&A)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.2 Enhanced Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ENHANCED WOODPECKER DATA FLOW (Original + Additions)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dataset (COCO) ğŸ†• NEW
    â”‚
    â”œâ”€â†’ coco_to_pairs.py ğŸ†• NEW
    â”‚       â”‚
    â”‚       â””â”€â†’ datasets/processed_pairs.json (100 samples)
    â”‚
    â”‚
    â”œâ”€â†’ inference_chunked.py ğŸ†• NEW
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Load BLIP-2, CLIP, GroundingDINO
    â”‚       â”‚
    â”‚       â”œâ”€â†’ For each chunk:
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€â†’ Generate caption (BLIP-2) âš¡ NEW
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€â†’ Apply Woodpecker Correction âœ… Original:
    â”‚       â”‚       â”‚       â”‚
    â”‚       â”‚       â”‚       â”œâ”€â†’ PreProcessor: Split sentences
    â”‚       â”‚       â”‚       â”œâ”€â†’ EntityExtractor: Extract entities
    â”‚       â”‚       â”‚       â”œâ”€â†’ Detector: Detect objects ğŸ”§ Enhanced
    â”‚       â”‚       â”‚       â”œâ”€â†’ Questioner: Generate questions
    â”‚       â”‚       â”‚       â”œâ”€â†’ Answerer: Answer questions
    â”‚       â”‚       â”‚       â”œâ”€â†’ ClaimGenerator: Generate claims
    â”‚       â”‚       â”‚       â””â”€â†’ Refiner: Refine text
    â”‚       â”‚       â”‚
    â”‚       â”‚       â””â”€â†’ Compute CLIP similarities âš¡ NEW
    â”‚       â”‚
    â”‚       â””â”€â†’ results/out_full.jsonl
    â”‚               â”‚
    â”‚               â””â”€â†’ Contains:
    â”‚                       â€¢ generated_text
    â”‚                       â€¢ corrected_output
    â”‚                       â€¢ clip_sim_generated âš¡ NEW
    â”‚                       â€¢ clip_sim_ground âš¡ NEW
    â”‚                       â€¢ clip_sim_corrected âš¡ NEW
    â”‚                       â€¢ hcs_score (placeholder)
    â”‚
    â”‚
    â”œâ”€â†’ inference_single.py ğŸ”„ MODIFIED
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Load image + caption
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Calculate HCS Score ğŸ†• NEW
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Run Correction Pipeline âœ… Original
    â”‚       â”‚
    â”‚       â””â”€â†’ Output: Corrected caption + HCS scores ğŸ†• NEW
    â”‚
    â”‚
    â””â”€â†’ compute_hcs_only.py ğŸ†• NEW
            â”‚
            â”œâ”€â†’ Load GroundingDINO
            â”‚
            â”œâ”€â†’ For each sample:
            â”‚       â”‚
            â”‚       â”œâ”€â†’ Extract entities from caption
            â”‚       â”‚
            â”‚       â”œâ”€â†’ Detect objects (GroundingDINO)
            â”‚       â”‚
            â”‚       â””â”€â†’ Calculate HCS score ğŸ†• NEW:
            â”‚               â€¢ Entity coverage
            â”‚               â€¢ Spatial consistency
            â”‚               â€¢ Detection confidence
            â”‚
            â””â”€â†’ results/out_full_hcs.jsonl
                    â”‚
                    â””â”€â†’ Contains:
                            â€¢ All previous fields
                            â€¢ hcs_score (computed) ğŸ†• NEW
                            â€¢ hcs_scores (detailed breakdown) ğŸ†• NEW


Parallel Processing Flow ğŸ†• NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
compute_hcs_parallel.py
    â”‚
    â”œâ”€â†’ Split JSONL into chunks
    â”‚
    â”œâ”€â†’ Launch parallel workers:
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Worker 1 (GPU 0) â†’ compute_hcs_only.py (chunk 1)
    â”‚       â”œâ”€â†’ Worker 2 (GPU 1) â†’ compute_hcs_only.py (chunk 2)
    â”‚       â”œâ”€â†’ Worker 3 (GPU 2) â†’ compute_hcs_only.py (chunk 3)
    â”‚       â””â”€â†’ Worker 4 (GPU 3) â†’ compute_hcs_only.py (chunk 4)
    â”‚
    â”œâ”€â†’ Monitor progress
    â”‚
    â”œâ”€â†’ Merge results
    â”‚
    â””â”€â†’ Output: Complete JSONL with HCS scores
```

**Legend:**
- âœ… **Original** = From original GitHub repository
- ğŸ†• **NEW** = Our addition
- ğŸ”„ **MODIFIED** = Enhanced from original
- âš¡ **Enhanced** = New features added
- ğŸ”§ **Enhanced** = Bug fixes/improvements

---

## Methodology

This section describes the methodology for both the original Woodpecker correction pipeline and our added HCS scoring system.

---

### 1. Original Woodpecker Methodology âœ… **From GitHub**

#### 1.1 Five-Stage Correction Pipeline

The original Woodpecker system implements a sequential 5-stage (actually 7-stage) correction pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: Image + Generated Caption              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: Preprocessing                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Split caption into individual sentences                      â”‚
â”‚  â€¢ Prepare structured data format                                â”‚
â”‚  Output: List of sentences                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: Key Concept Extraction                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Extract named entities from each sentence                    â”‚
â”‚  â€¢ Use spaCy NLP for entity recognition                         â”‚
â”‚  â€¢ Format: obj1.obj2.obj3...                                    â”‚
â”‚  Output: Named entities per sentence                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: Visual Knowledge Validation                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Use GroundingDINO to detect objects in image                â”‚
â”‚  â€¢ Match detected objects with extracted entities                â”‚
â”‚  â€¢ Crop detected regions and cache                              â”‚
â”‚  â€¢ Filter by box_threshold and area_threshold                   â”‚
â”‚  Output: Entity detection results with bounding boxes          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: Question Formulation                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Generate validation questions for each detected entity       â”‚
â”‚  â€¢ Use LLM (GPT/OpenAI API) to formulate questions             â”‚
â”‚  â€¢ Questions verify presence/attributes of entities             â”‚
â”‚  Output: List of validation questions                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5: Visual Knowledge Answering                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Use BLIP-2 to answer questions on image regions              â”‚
â”‚  â€¢ Validate each entity claim against visual evidence           â”‚
â”‚  â€¢ Generate answers for each question                            â”‚
â”‚  Output: Answers validating entity claims                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 6: Visual Claim Generation                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Convert Q&A pairs into factual claims                        â”‚
â”‚  â€¢ Use QA2Claim model (T5-based)                                â”‚
â”‚  â€¢ Generate corrected statements based on visual evidence       â”‚
â”‚  Output: Corrected claims per entity                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 7: Hallucination Correction                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Replace hallucinated entities with corrected claims         â”‚
â”‚  â€¢ Use LLM to refine and integrate corrections                  â”‚
â”‚  â€¢ Generate final corrected caption                             â”‚
â”‚  Output: Corrected caption                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 1.2 Component Details

**PreProcessor** (`models/preprocessor.py`)
- Splits input description into sentences
- Prepares structured format for downstream processing

**EntityExtractor** (`models/entity_extractor.py`)
- Extracts named entities using NLP techniques
- Uses spaCy for entity recognition
- Formats entities as dot-separated strings

**Detector** (`models/detector.py`)
- Uses GroundingDINO for open-set object detection
- Detects objects mentioned in text within images
- Crops detected regions and caches them
- Filters detections by confidence and area thresholds
- **ğŸ”§ Enhanced**: Added boundary clipping to prevent "tile cannot extend outside image" errors

**Questioner** (`models/questioner.py`)
- Generates validation questions using LLM API
- Creates questions to verify entity presence/attributes
- Uses OpenAI GPT API for question generation

**Answerer** (`models/answerer.py`)
- Uses BLIP-2 (Salesforce/blip2-flan-t5-xxl) for visual QA
- Answers questions about specific image regions
- Validates entity claims against visual evidence

**ClaimGenerator** (`models/claim_generator.py`)
- Converts Q&A pairs into factual claims
- Uses QA2Claim model (khhuang/zerofec-qa2claim-t5-base)
- Generates corrected statements

**Refiner** (`models/refiner.py`)
- Integrates corrections into final caption
- Uses LLM to refine and polish corrected text
- Produces final hallucination-free output

---

### 2. HCS Scoring Methodology ğŸ†• **Our Addition**

#### 2.1 HCS Pipeline Flow

The HCS system provides a quantitative measure of hallucination likelihood without performing correction. **This is a new module we developed and added to the original Woodpecker system.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: Image + Caption                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: Entity Extraction                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Extract entities from caption text                          â”‚
â”‚  â€¢ Simple token-based extraction with stop-word filtering      â”‚
â”‚  Output: List of entities                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: Object Detection                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Use GroundingDINO to detect entities in image               â”‚
â”‚  â€¢ Match text entities with visual detections                   â”‚
â”‚  â€¢ Extract bounding boxes and detection counts                 â”‚
â”‚  Output: Entity detection information                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: Score Calculation                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Calculate three sub-scores:                                    â”‚
â”‚                                                                  â”‚
â”‚  1. Entity Coverage Score (40% weight)                         â”‚
â”‚     â€¢ Ratio of text entities detected in image                  â”‚
â”‚                                                                  â”‚
â”‚  2. Spatial Consistency Score (30% weight)                      â”‚
â”‚     â€¢ Consistency of spatial relationships                      â”‚
â”‚                                                                  â”‚
â”‚  3. Detection Confidence Score (30% weight)                     â”‚
â”‚     â€¢ Quality and confidence of detections                      â”‚
â”‚                                                                  â”‚
â”‚  Overall HCS = 0.4 Ã— Coverage + 0.3 Ã— Spatial + 0.3 Ã— Conf    â”‚
â”‚  Output: HCS score (0-1, higher = less hallucination)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.2 HCS Score Components

1. **Entity Coverage Score**: Measures how many entities mentioned in text are actually detected in the image
   - Formula: `covered_entities / total_text_entities`
   - Range: 0.0 to 1.0
   - Weight: 40%

2. **Spatial Consistency Score**: Evaluates consistency of spatial relationships
   - Based on spatial keywords (left, right, above, below, etc.)
   - Normalized by number of detected entities
   - Weight: 30%

3. **Detection Confidence Score**: Reflects quality of object detections
   - Based on detection counts and confidence values
   - Normalized detection quality metric
   - Weight: 30%

#### 2.3 HCS Implementation Details

**Module**: `modules/hallucination_detector.py`
- `HallucinationConfidenceScorer` class
- Global scorer instance to avoid reinitialization
- Device-aware computation (CPU/CUDA)
- Returns detailed score breakdown

**Integration Points**:
- Can be used independently via `compute_hcs_only.py`
- Can be integrated into correction pipeline via `inference_single.py`
- Supports parallel processing via `compute_hcs_parallel.py`

---

## Experiments

This section describes our experimental setup, evaluation methodology, and results.

---

### 1. Experimental Setup

#### 1.1 Dataset Preparation

- **Source**: COCO dataset (val2017)
- **Processing**: Convert COCO annotations to image-caption pairs
- **Script**: `coco_to_pairs.py` ğŸ†• NEW
- **Format**: JSON with `{image, query, text}` structure
- **Current Experiment**: Limited to 100 samples for evaluation

#### 1.2 Evaluation Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXPERIMENTAL PIPELINE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 1: Dataset Preparation ğŸ†• NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
coco_to_pairs.py
  â†“
  Generates: datasets/processed_pairs.json
  Format: [{image, query, text}, ...]
  Limit: 100 samples


Phase 2: Caption Generation & Correction
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
inference_chunked.py ğŸ†• NEW
  â†“
  Input: datasets/processed_pairs.json
  Models: BLIP-2 (caption generation)
  Process:
    â€¢ Load images in batches
    â€¢ Generate captions using BLIP-2 âš¡ NEW
    â€¢ Apply Woodpecker correction pipeline âœ… Original
    â€¢ Compute CLIP similarity scores âš¡ NEW
  Output: results/out_full.jsonl
  Format: {
    image, query, generated_text, 
    ground_truth, corrected_output,
    clip_sim_generated âš¡ NEW, clip_sim_ground âš¡ NEW, 
    clip_sim_corrected âš¡ NEW, hcs_score (placeholder)
  }


Phase 3: HCS Computation (Post-processing) ğŸ†• NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
compute_hcs_only.py
  â†“
  Input: results/out_full.jsonl
  Process:
    â€¢ Load pre-generated captions
    â€¢ Extract entities
    â€¢ Detect objects using GroundingDINO
    â€¢ Calculate HCS scores
    â€¢ Cache results for duplicate captions
  Output: results/out_full_hcs.jsonl
  Features:
    â€¢ Processes 100 samples
    â€¢ Checkpoint saving every 100 samples
    â€¢ Resume capability
    â€¢ GPU memory optimization
```

---

### 2. Key Scripts and Their Roles

#### 2.1 **inference_chunked.py** ğŸ†• NEW
- **Purpose**: Main inference pipeline with correction
- **Features**:
  - Chunked processing for large datasets
  - Batch processing with DataLoader
  - Multi-GPU support
  - BLIP-2 caption generation
  - Woodpecker correction integration âœ… Original
  - CLIP similarity computation âš¡ NEW
  - Auto-resume functionality
- **Output**: JSONL with generated, corrected captions and CLIP scores

#### 2.2 **compute_hcs_only.py** ğŸ†• NEW
- **Purpose**: Separate HCS computation for post-processing
- **Features**:
  - Loads pre-generated captions
  - Computes HCS scores independently
  - Caption caching for duplicates
  - Checkpoint saving
  - GPU memory optimization
  - Boundary clipping fix for tile errors ğŸ”§ Enhanced
- **Optimizations**:
  - Global model loading
  - Caption caching
  - CUDA optimizations (cuDNN benchmark, TF32)
  - Reduced logging overhead

#### 2.3 **compute_hcs_parallel.py** ğŸ†• NEW
- **Purpose**: Parallel HCS computation wrapper
- **Features**:
  - Splits JSONL into chunks
  - Multi-worker parallel processing
  - GPU assignment per worker
  - Progress tracking
  - Automatic merging of results
- **Speedup**: 3-4x with 4 workers

#### 2.4 **inference_batch.py** ğŸ†• NEW
- **Purpose**: Simple batch inference without correction
- **Features**:
  - BLIP-2 caption generation
  - CLIP similarity computation
  - Basic evaluation pipeline

---

### 3. Model Components

#### Vision-Language Models Used:

1. **BLIP-2** (Salesforce/blip2-flan-t5-xxl)
   - Purpose: Caption generation and visual QA
   - Usage: Primary caption generator and answerer

2. **CLIP** (OpenAI CLIP) âš¡ NEW
   - Purpose: Image-text similarity computation
   - Usage: Evaluate caption quality via cosine similarity

3. **GroundingDINO**
   - Purpose: Open-set object detection
   - Usage: Detect entities mentioned in text within images
   - Configuration: GroundingDINO_SwinT_OGC
   - Thresholds: box_threshold=0.35, area_threshold=0.001

4. **LLM APIs** (OpenAI GPT)
   - Purpose: Question generation and text refinement
   - Usage: Questioner and Refiner stages

5. **QA2Claim Model** (khhuang/zerofec-qa2claim-t5-base)
   - Purpose: Convert Q&A pairs to factual claims
   - Usage: Claim generation stage

---

### 4. Evaluation Metrics

#### 4.1 CLIP Similarity Scores âš¡ NEW

- **clip_sim_generated**: Similarity between image and generated caption
- **clip_sim_ground**: Similarity between image and ground truth
- **clip_sim_corrected**: Similarity between image and corrected caption
- **Range**: -1.0 to 1.0 (higher = better alignment)

#### 4.2 HCS Score ğŸ†• NEW

- **overall_hcs_score**: Overall hallucination confidence score
- **Range**: 0.0 to 1.0 (higher = less hallucination)
- **Components**:
  - entity_coverage_score
  - spatial_consistency_score
  - detection_confidence_score

---

### 5. Performance Optimizations

#### Implemented Optimizations:

1. **Global Model Loading** âš¡ Enhanced
   - Reuses HCS scorer instance across samples
   - Eliminates repeated initialization overhead
   - **Time saved**: ~2 hours for 25k samples

2. **Caption Caching** âš¡ Enhanced
   - Caches HCS results for duplicate captions
   - Dictionary lookup for instant results
   - **Time saved**: 20-40 minutes (15-30% duplicate rate)

3. **CUDA Optimizations** âš¡ Enhanced
   - cuDNN benchmark mode
   - TensorFloat-32 (TF32) for A100 GPUs
   - Gradient computation disabled
   - **Speedup**: 10-15% GPU operations

4. **Parallel Processing** ğŸ†• NEW
   - Multi-worker HCS computation
   - GPU assignment per worker
   - **Speedup**: 3-4x with 4 workers

5. **Chunked Processing** âš¡ Enhanced
   - Processes datasets in chunks
   - Memory-efficient for large datasets
   - Checkpoint saving for recovery

6. **Boundary Clipping Fix** ğŸ”§ Enhanced
   - Prevents "tile cannot extend outside image" errors
   - Clips bounding boxes to image boundaries
   - Validates box coordinates before cropping

---

### 6. Experimental Results

#### 6.1 Original Woodpecker Results (from Paper)

Based on the original Woodpecker paper:

**POPE Benchmark Results:**
- **MiniGPT-4**: +30.66% accuracy improvement
- **mPLUG-Owl**: +24.33% accuracy improvement

**MME Benchmark Results:**
- Improvements in both object- and attribute-level hallucinations

**LLaVA-QA90 Results:**
- Improvements in accuracy and detailedness metrics

#### 6.2 Our Experiment Configuration

**Sample Limitation:**
- **Total samples**: 100 (for evaluation/testing)
- **Applied in**:
  - `compute_hcs_only.py`: Line 96 (`lines = all_lines[:100]`)
  - `inference_chunked.py`: Line 170 (`data = all_data[:100]`)
  - `inference_batch.py`: Line 44 (`data = all_data[:100]`)

**Processing Flow:**
```
100 COCO Samples
    â†“
inference_chunked.py (with correction) ğŸ†• NEW
    â†“
results/out_full.jsonl (100 samples with captions)
    â†“
compute_hcs_only.py (HCS scoring) ğŸ†• NEW
    â†“
results/out_full_hcs.jsonl (100 samples with HCS scores)
```

---

## Key Features and Innovations

### 1. Training-Free Approach âœ… Original
- No model retraining required
- Works with any pre-trained MLLM
- Post-processing correction pipeline

### 2. Interpretability âœ… Original + ğŸ†• Enhanced
- Intermediate outputs at each stage âœ… Original
- Entity detection visualization âœ… Original
- Question-answer pairs for validation âœ… Original
- Detailed HCS score breakdown ğŸ†• NEW

### 3. Modular Design âœ… Original
- Each stage is independent
- Easy to modify or replace components
- Clear separation of concerns

### 4. Performance Optimizations âš¡ Enhanced
- Chunked processing for large datasets
- Parallel HCS computation ğŸ†• NEW
- Caching mechanisms ğŸ†• NEW
- GPU memory optimization ğŸ†• NEW

### 5. Robustness ğŸ”§ Enhanced
- Error handling at each stage
- Boundary clipping for object detection ğŸ”§ Enhanced
- Fallback mechanisms
- Checkpoint saving for recovery ğŸ†• NEW

---

## File Structure

```
Woodpecker/
â”œâ”€â”€ models/                        âœ… Original (from GitHub)
â”‚   â”œâ”€â”€ preprocessor.py          # Stage 1: Sentence splitting
â”‚   â”œâ”€â”€ entity_extractor.py      # Stage 2: Entity extraction
â”‚   â”œâ”€â”€ detector.py              # Stage 3: Object detection (ğŸ”§ Enhanced with boundary fix)
â”‚   â”œâ”€â”€ questioner.py            # Stage 4: Question generation
â”‚   â”œâ”€â”€ answerer.py              # Stage 5: Visual QA
â”‚   â”œâ”€â”€ claim_generator.py       # Stage 6: Claim generation
â”‚   â”œâ”€â”€ refiner.py               # Stage 7: Text refinement
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”‚
â”œâ”€â”€ modules/                       ğŸ†• NEW
â”‚   â””â”€â”€ hallucination_detector.py  # HCS scoring module (Our Addition)
â”‚
â”œâ”€â”€ inference_chunked.py          ğŸ†• NEW - Enhanced batch inference with CLIP scoring
â”œâ”€â”€ inference_batch.py            ğŸ†• NEW - Simple batch inference
â”œâ”€â”€ inference_single.py           ğŸ”„ MODIFIED - Added HCS integration
â”œâ”€â”€ compute_hcs_only.py          ğŸ†• NEW - Standalone HCS computation
â”œâ”€â”€ compute_hcs_parallel.py      ğŸ†• NEW - Parallel HCS wrapper
â”œâ”€â”€ vis_corrector.py              âœ… Original - Corrector pipeline orchestrator
â”œâ”€â”€ coco_to_pairs.py              ğŸ†• NEW - Dataset preparation utility
â”œâ”€â”€ gradio_demo.py                âœ… Original - Web demo interface
â”‚
â”œâ”€â”€ requirements.txt               âœ… Original
â”œâ”€â”€ README.md                      âœ… Original (from GitHub)
â”œâ”€â”€ OPTIMIZATION_GUIDE.md          ğŸ†• NEW - Our optimization documentation
â””â”€â”€ PROJECT_DESCRIPTION.md         ğŸ†• NEW - This document (Our documentation)

Legend:
âœ… Original = From original GitHub repository
ğŸ†• NEW = Our addition
ğŸ”„ MODIFIED = Enhanced from original
ğŸ”§ Enhanced = Bug fixes/improvements added
```

---

## Conclusion

Woodpecker represents a novel approach to hallucination correction in MLLMs, offering a training-free, interpretable, and effective solution. The system's modular design allows for easy integration with existing MLLMs while providing significant improvements in accuracy and reliability.

### Our Contributions Summary

Building upon the original Woodpecker system from GitHub, we have made significant enhancements:

1. **ğŸ†• HCS Scoring System**: Added a complete Hallucination Confidence Scoring module that provides quantitative metrics for hallucination detection without requiring correction. This enables objective evaluation and comparison of different captions.

2. **ğŸ†• Enhanced Evaluation Pipeline**: Created comprehensive batch processing scripts (`inference_chunked.py`, `inference_batch.py`) with CLIP similarity computation, enabling large-scale evaluation of correction effectiveness.

3. **ğŸ†• Scalability Improvements**: Implemented parallel processing capabilities (`compute_hcs_parallel.py`) and performance optimizations (caching, global model loading, CUDA optimizations) for efficient processing of large datasets.

4. **ğŸ”§ Bug Fixes**: Fixed critical issues like the "tile cannot extend outside image" error in the detector module, improving system robustness.

5. **ğŸ“š Documentation**: Created comprehensive documentation including optimization guides and detailed project descriptions.

The addition of HCS scoring provides quantitative evaluation metrics for hallucination detection, making it a comprehensive solution for improving MLLM outputs. Our enhancements make the system more scalable, robust, and suitable for large-scale evaluation tasks.

---

## References

- **Paper**: [Woodpecker: Hallucination correction for multimodal large language models](https://arxiv.org/pdf/2310.16045.pdf)
- **GitHub**: Original Woodpecker repository
- **Baseline Models**: LLaVA, mPLUG-Owl, Otter, MiniGPT-4
- **Dependencies**: GroundingDINO, BLIP-2, CLIP, spaCy, Transformers

---

*Document generated for Woodpecker project evaluation and documentation*
